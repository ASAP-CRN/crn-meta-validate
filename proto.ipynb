{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# wrape this in try/except to make suing the ReportCollector portable\n",
    "# probably an abstract base class would be better\n",
    "try:\n",
    "    import streamlit as st\n",
    "    print(\"Streamlit imported successfully\")\n",
    "\n",
    "except ImportError:\n",
    "    class DummyStreamlit:\n",
    "        @staticmethod\n",
    "        def markdown(self,msg):\n",
    "            pass\n",
    "        def error(self,msg):\n",
    "            pass\n",
    "        def header(self,msg):\n",
    "            pass        \n",
    "        def subheader(self,msg):\n",
    "            pass    \n",
    "        def divider(self):\n",
    "            pass\n",
    "    st = DummyStreamlit()\n",
    "    print(\"Streamlit NOT successfully\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE_SHEET_ID = \"1xjxLftAyD0B8mPuOKUp5cKMKjkcsrp_zr9yuVULBLG8\"\n",
    "GOOGLE_SHEET_ID = \"1c0z5KvRELdT2AtQAH2Dus8kwAyyLrR0CROhKOjpU4Vc\"\n",
    "\n",
    "\n",
    "team = \"Scherzer\"\n",
    "HOME = Path.home()\n",
    "base_path = HOME / f\"Projects/ASAP/asap-cloud-data-processing-resources/asap-ids/teams/\"\n",
    "test_path = base_path / f\"{team.lower()}/input\"\n",
    "\n",
    "NULL = \"NA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_CDE(metadata_version:str=\"v3.0-beta\", local=False):\n",
    "    \"\"\"\n",
    "    Load CDE from local csv and cache it, return a dataframe and dictionary of dtypes\n",
    "    \"\"\"\n",
    "    # Construct the path to CSD.csv\n",
    "\n",
    "    if metadata_version == \"v1\":\n",
    "        sheet_name = \"ASAP_CDE_v1\"\n",
    "    elif metadata_version == \"v2\":\n",
    "        sheet_name = \"ASAP_CDE_v2\"\n",
    "    elif metadata_version == \"v2.1\":\n",
    "        sheet_name = \"ASAP_CDE_v2.1\"\n",
    "    elif metadata_version in [\"v3.0\",\"v3.0-beta\"]:\n",
    "        sheet_name = \"ASAP_CDE_v3.0-beta\"\n",
    "    else:\n",
    "        sheet_name = \"ASAP_CDE_v2.1\"\n",
    "\n",
    "\n",
    "    if metadata_version in [\"v1\",\"v2\",\"v2.1\",\"v3.0-beta\"]:\n",
    "        print(f\"metadata_version: {sheet_name}\")\n",
    "    else:\n",
    "        print(f\"Unsupported metadata_version: {sheet_name}\")\n",
    "        return 0,0\n",
    "    \n",
    "    cde_url = f\"https://docs.google.com/spreadsheets/d/{GOOGLE_SHEET_ID}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "    if local:\n",
    "        cde_url = f\"{sheet_name}.csv\"\n",
    "    \n",
    "    try:\n",
    "        CDE_df = pd.read_csv(cde_url)\n",
    "        read_source = \"url\" if not local else \"local file\"\n",
    "        print(f\"read {read_source}\")\n",
    "    except:\n",
    "        CDE_df = pd.read_csv(f\"{sheet_name}.csv\")\n",
    "        print(\"read local file\")\n",
    "\n",
    "    return CDE_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata_version: ASAP_CDE_v3.0-beta\n",
      "read local file\n"
     ]
    }
   ],
   "source": [
    "CDE_df = read_CDE(metadata_version=\"v3.0-beta\", local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Table', 'Field', 'Description', 'DataType', 'Required', 'Validation',\n",
       "       'V0', 'comment', 'denormalized', 'dataset relavent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CDE_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['STUDY', 'PROTOCOL', 'SUBJECT', 'CLINPATH', 'SAMPLE',\n",
       "       'ASSAY_scRNAseq', 'DATA', 'PMDBS'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CDE_df[\"Table\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_meta_table(table_path):\n",
    "    # read the whole table\n",
    "    try:\n",
    "        table_df = pd.read_csv(table_path,dtype=str)\n",
    "    except UnicodeDecodeError:\n",
    "        table_df = pd.read_csv(table_path, encoding='latin1',dtype=str)\n",
    "\n",
    "    # drop the first column if it is just the index\n",
    "    if table_df.columns[0] == \"Unnamed: 0\":\n",
    "        table_df = table_df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    \n",
    "    return table_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading STUDY table\n",
      "Loading PROTOCOL table\n",
      "Loading SUBJECT table\n",
      "Loading CLINPATH table\n",
      "Loading SAMPLE table\n",
      "Table ASSAY_scRNAseq does not exist\n",
      "Loading DATA table\n",
      "Table PMDBS does not exist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tables = {}\n",
    "for table in CDE_df[\"Table\"].unique():\n",
    "    # load table\n",
    "    table_path = test_path / f\"{table}.csv\"\n",
    "    if not table_path.exists():\n",
    "        print(f\"Table {table} does not exist\")\n",
    "    else:\n",
    "        df = pd.read_csv(table_path,dtype=\"str\")\n",
    "        tables[table] = df\n",
    "        print(f\"Loading {table} table\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = {}\n",
    "for table in CDE_df[\"Table\"].unique():\n",
    "    # load table\n",
    "    table_path = test_path / f\"{table}.csv\"\n",
    "    df = pd.read_csv(table_path,dtype=\"str\")\n",
    "    df.replace({\"\":NULL, pd.NA:NULL}, inplace=True)\n",
    "    tables[table] = df\n",
    "    specific_cde_df = CDE_df[CDE_df['Table'] == table]\n",
    "\n",
    "\n",
    "    print(f\"___________{table}__________\")\n",
    "    for field in specific_cde_df[\"Field\"]:\n",
    "        entry_idx = specific_cde_df[\"Field\"]==field\n",
    "\n",
    "        opt_req = \"REQUIRED\" if specific_cde_df.loc[entry_idx, \"Required\"].item()==\"Required\" else \"OPTIONAL\"\n",
    "\n",
    "        if field not in df.columns:\n",
    "            print(f\"missing {opt_req} column {field}\")\n",
    "\n",
    "        else:\n",
    "            datatype = specific_cde_df.loc[entry_idx,\"DataType\"]\n",
    "            if datatype.item() == \"Integer\":\n",
    "                # recode \"Unknown\" as NULL\n",
    "                df.replace({\"Unknown\":NULL, \"unknown\":NULL}, inplace=True)\n",
    "                df[field].apply(lambda x: int(x) if x!=NULL else x )\n",
    "                # test that all are integer or NULL, flag NULL entries\n",
    "            elif datatype.item() == \"Float\":\n",
    "                # recode \"Unknown\" as NULL\n",
    "                df.replace({\"Unknown\":NULL, \"unknown\":NULL}, inplace=True)\n",
    "                df[field].apply(lambda x: float(x) if x!=NULL else x )\n",
    "                # test that all are float or NULL, flag NULL entries\n",
    "            elif datatype.item() == \"Enum\":\n",
    "\n",
    "                valid_values = eval(specific_cde_df.loc[entry_idx,\"Validation\"].item())\n",
    "                entries = df[field]\n",
    "                valid_entries = entries.apply(lambda x: x in valid_values)\n",
    "                invalid_values = entries[~valid_entries].unique()\n",
    "                n_invalid = invalid_values.shape[0]\n",
    "                if n_invalid > 0:\n",
    "                    print(f\">> {field} has {n_invalid} invalid entries. \")\n",
    "                    valstr = \", \".join(valid_values)\n",
    "                    print(f\"              recode from {valstr}\")\n",
    "            else: #dtype == String\n",
    "                pass\n",
    "            \n",
    "            n_null = (df[field]==NULL).sum()\n",
    "            if n_null > 0:            \n",
    "                print(f\"{opt_req} {field} has {n_null}/{df.shape[0]} NULL entries \")\n",
    "\n",
    "    # validate_table(df, specific_cde_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"CLINPATH\"\n",
    "\n",
    "# load table\n",
    "table_path = test_path / f\"{table}.csv\"\n",
    "df = pd.read_csv(table_path,dtype=\"str\")\n",
    "df.replace({\"\":NULL, pd.NA:NULL}, inplace=True)\n",
    "tables[table] = df\n",
    "specific_cde_df = CDE_df[CDE_df['Table'] == table]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_log(log_file):\n",
    "    \"\"\" grab logged information from the log file.\"\"\"\n",
    "    with open(log_file, 'r') as f:\n",
    "        report_content = f.read()\n",
    "    return report_content\n",
    "\n",
    "def columnize( itemlist ):\n",
    "    NEWLINE_DASH = ' \\n- '\n",
    "    if len(itemlist) > 1:\n",
    "        return f\"- {itemlist[0]}{NEWLINE_DASH.join(itemlist[1:])}\"\n",
    "    else:\n",
    "        return f\"- {itemlist[0]}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ReportCollector:\n",
    "    \"\"\"\n",
    "    Class to collect and log messages, errors, and markdown to a log file and/or streamlit\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, destination=\"both\"):\n",
    "        self.entries = []\n",
    "        self.filename = None\n",
    "\n",
    "        if destination in [\"both\", \"streamlit\"]:\n",
    "            self.publish_to_streamlit = True\n",
    "        else:\n",
    "            self.publish_to_streamlit = False\n",
    "\n",
    "\n",
    "    def add_markdown(self, msg):\n",
    "        self.entries.append((\"markdown\", msg))\n",
    "        if self.publish_to_streamlit:\n",
    "            st.markdown(msg)\n",
    "\n",
    "\n",
    "    def add_error(self, msg):\n",
    "        self.entries.append((\"error\", msg))\n",
    "        if self.publish_to_streamlit:\n",
    "            st.error(msg)\n",
    "\n",
    "    def add_header(self, msg):\n",
    "        self.entries.append((\"header\", msg))\n",
    "        if self.publish_to_streamlit:    \n",
    "            st.header(msg)\n",
    "\n",
    "    def add_subheader(self, msg):\n",
    "        self.entries.append((\"subheader\", msg))\n",
    "        if self.publish_to_streamlit:    \n",
    "            st.subheader(msg)\n",
    "\n",
    "    def add_divider(self):\n",
    "        self.entries.append((\"divider\", None))\n",
    "        if self.publish_to_streamlit:    \n",
    "            st.divider()\n",
    "\n",
    "    \n",
    "    def write_to_file(self, filename):\n",
    "        self.filename = filename\n",
    "        with open(filename, 'w') as f:\n",
    "            report_content = self.get_log()\n",
    "            f.write(report_content)\n",
    "    \n",
    "\n",
    "    def get_log(self):\n",
    "        \"\"\" grab logged information from the log file.\"\"\"\n",
    "        report_content = []\n",
    "        for msg_type, msg in self.entries:\n",
    "            if msg_type == \"markdown\":\n",
    "                report_content += msg + '\\n'\n",
    "            elif msg_type == \"error\":\n",
    "                report_content += f\"🚨⚠️❗ **{msg}**\\n\"\n",
    "            elif msg_type == \"header\":\n",
    "                report_content += f\"# {msg}\\n\"\n",
    "            elif msg_type == \"subheader\":\n",
    "                report_content += f\"## {msg}\\n\"\n",
    "            elif msg_type == \"divider\":\n",
    "                report_content += 60*'-' + '\\n'\n",
    "        \n",
    "        return \"\".join(report_content)\n",
    "\n",
    "    def reset(self):\n",
    "        self.entries = []\n",
    "        self.filename = None\n",
    "\n",
    "    def print_log(self):\n",
    "        print(self.get_log())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_table(df: pd.DataFrame, table_name: str, specific_cde_df: pd.DataFrame, out: ReportCollector ):\n",
    "    \"\"\"\n",
    "    Validate the table against the specific table entries from the CDE\n",
    "    \"\"\"\n",
    "    def my_str(x):\n",
    "        return f\"'{str(x)}'\"\n",
    "        \n",
    "    missing_required = []\n",
    "    missing_optional = []\n",
    "    null_fields = []\n",
    "    invalid_entries = []\n",
    "    total_rows = df.shape[0]\n",
    "    for field in specific_cde_df[\"Field\"]:\n",
    "        entry_idx = specific_cde_df[\"Field\"]==field\n",
    "\n",
    "        opt_req = \"REQUIRED\" if specific_cde_df.loc[entry_idx, \"Required\"].item()==\"Required\" else \"OPTIONAL\"\n",
    "\n",
    "        if field not in df.columns:\n",
    "            if opt_req == \"REQUIRED\":\n",
    "                missing_required.append(field)\n",
    "            else:\n",
    "                missing_optional.append(field)\n",
    "\n",
    "            # print(f\"missing {opt_req} column {field}\")\n",
    "\n",
    "        else:\n",
    "            datatype = specific_cde_df.loc[entry_idx,\"DataType\"]\n",
    "            if datatype.item() == \"Integer\":\n",
    "                # recode \"Unknown\" as NULL\n",
    "                df.replace({\"Unknown\":NULL, \"unknown\":NULL}, inplace=True)\n",
    "                df[field].apply(lambda x: int(x) if x!=NULL else x )\n",
    "                # test that all are integer or NULL, flag NULL entries\n",
    "            elif datatype.item() == \"Float\":\n",
    "                # recode \"Unknown\" as NULL\n",
    "                df.replace({\"Unknown\":NULL, \"unknown\":NULL}, inplace=True)\n",
    "                df[field].apply(lambda x: float(x) if x!=NULL else x )\n",
    "                # test that all are float or NULL, flag NULL entries\n",
    "            elif datatype.item() == \"Enum\":\n",
    "\n",
    "                valid_values = eval(specific_cde_df.loc[entry_idx,\"Validation\"].item())\n",
    "                entries = df[field]\n",
    "                valid_entries = entries.apply(lambda x: x in valid_values)\n",
    "                invalid_values = entries[~valid_entries].unique()\n",
    "                n_invalid = invalid_values.shape[0]\n",
    "                if n_invalid > 0:\n",
    "                    valstr = ', '.join(map(my_str, valid_values))\n",
    "                    invalstr = ', '.join(map(my_str,invalid_values))\n",
    "            else: #dtype == String\n",
    "                pass\n",
    "            \n",
    "            n_null = (df[field]==NULL).sum()\n",
    "            if n_null > 0:            \n",
    "                null_fields.append((opt_req, field, n_null))\n",
    "\n",
    "\n",
    "    # now compose report...\n",
    "    if len(missing_required) > 0:\n",
    "        out.add_error(f\"Missing Required Fields in {table_name}: {', '.join(missing_required)}\")\n",
    "    else:\n",
    "        out.add_markdown(f\"All required fields are present in *{table_name}* table.\")\n",
    "\n",
    "    if len(missing_optional) > 0:\n",
    "        out.add_error(f\"Missing Optional Fields in {table_name}: {', '.join(missing_optional)}\")\n",
    "    \n",
    "\n",
    "    if len(null_fields) > 0:\n",
    "        # print(f\"{opt_req} {field} has {n_null}/{df.shape[0]} NULL entries \")\n",
    "        out.add_error(f\"{len(null_fields)} Fields with empty (NULL) values:\")\n",
    "        for opt_req, field, count in null_fields:\n",
    "            out.add_markdown(f\"\\n\\t- {field}: {count}/{total_rows} empty rows ({opt_req})\")\n",
    "    else:\n",
    "        out.add_markdown(f\"No empty entries (NULL) found .\")\n",
    "\n",
    "\n",
    "    if len(invalid_entries) > 0:\n",
    "        out.add_error(f\"{len(invalid_entries)} Fields with invalid entries:\")\n",
    "        for opt_req, field, count, valstr, invalstr in invalid_entries:\n",
    "            str_out = f\"- _*{field}*_:  invalid values 💩{invalstr}\\n\"\n",
    "            str_out += f\"    - valid ➡️ {valstr}\"\n",
    "            out.add_markdown(str_out)\n",
    "    else:\n",
    "        out.add_markdown(f\"No invalid entries found in Enum fields.\")\n",
    "\n",
    "\n",
    "    return df, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ReportCollector(\"log\")\n",
    "\n",
    "df_out, report = validate_table(df,table, specific_cde_df, report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields are present in *CLINPATH* table.\n",
      "🚨⚠️❗ **Missing Optional Fields in CLINPATH: ASAP_dataset_id, ASAP_team_id, ASAP_subject_id**\n",
      "🚨⚠️❗ **29 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- path_autopsy_dx_main: 1/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_second_dx: 3/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_third_dx: 11/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_fourth_dx: 36/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_fifth_dx: 59/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_sixth_dx: 69/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_seventh_dx: 81/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_eight_dx: 91/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_year_death: 2/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- other_cause_death_1: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- other_cause_death_2: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_braak_asyn: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_cerad: 44/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_thal: 21/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- known_pathogenic_mutation: 68/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- PD_pathogenic_mutation: 68/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_mckeith: 6/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- sn_neuronal_loss: 6/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_infarcs: 3/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_ri: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_aa_a: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_aa_b: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_aa_c: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- TDP43: 32/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- arteriolosclerosis_severity_scale: 70/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- amyloid_angiopathy_severity_scale: 88/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_ad_level: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- dig_slide_avail: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- quant_path_avail: 94/94 empty rows (OPTIONAL)\n",
      "No invalid entries found in Enum fields.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report.print_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading STUDY table\n",
      "🚨⚠️❗ **Missing Required Fields in STUDY: submitter_email, numbe_samples, sample_types**\n",
      "🚨⚠️❗ **Missing Optional Fields in STUDY: ASAP_dataset_id, ASAP_team_id, PI_ORCID, alternate_dataset_id**\n",
      "🚨⚠️❗ **5 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- other_funding_source: 1/1 empty rows (REQUIRED)\n",
      "\n",
      "\t- publication_DOI: 1/1 empty rows (REQUIRED)\n",
      "\n",
      "\t- publication_PMID: 1/1 empty rows (REQUIRED)\n",
      "\n",
      "\t- PI_google_scholar_id: 1/1 empty rows (OPTIONAL)\n",
      "\n",
      "\t- preprocessing_references: 1/1 empty rows (OPTIONAL)\n",
      "No invalid entries found in Enum fields.\n",
      "\n",
      "Loading PROTOCOL table\n",
      "All required fields are present in *PROTOCOL* table.\n",
      "🚨⚠️❗ **Missing Optional Fields in PROTOCOL: ASAP_dataset_id, ASAP_team_id**\n",
      "No empty entries (NULL) found .\n",
      "No invalid entries found in Enum fields.\n",
      "\n",
      "Loading SUBJECT table\n",
      "All required fields are present in *SUBJECT* table.\n",
      "🚨⚠️❗ **Missing Optional Fields in SUBJECT: ASAP_dataset_id, ASAP_team_id, ASAP_subject_id**\n",
      "🚨⚠️❗ **15 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- primary_diagnosis_text: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- AMPPD_id: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- GP2_id: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- ethnicity: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- family_history: 86/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- age_at_onset: 49/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- age_at_diagnosis: 59/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- first_motor_symptom: 63/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- hx_melanoma: 93/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- education_level: 2/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- smoking_status: 7/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- smoking_years: 64/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- APOE_e4_status: 2/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- cognitive_status: 11/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- time_from_baseline: 94/94 empty rows (OPTIONAL)\n",
      "No invalid entries found in Enum fields.\n",
      "\n",
      "Loading CLINPATH table\n",
      "All required fields are present in *CLINPATH* table.\n",
      "🚨⚠️❗ **Missing Optional Fields in CLINPATH: ASAP_dataset_id, ASAP_team_id, ASAP_subject_id**\n",
      "🚨⚠️❗ **29 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- path_autopsy_dx_main: 1/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_second_dx: 3/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_third_dx: 11/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_fourth_dx: 36/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_fifth_dx: 59/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_sixth_dx: 69/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_seventh_dx: 81/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_eight_dx: 91/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_year_death: 2/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- other_cause_death_1: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- other_cause_death_2: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_braak_asyn: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_cerad: 44/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_thal: 21/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- known_pathogenic_mutation: 68/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- PD_pathogenic_mutation: 68/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_mckeith: 6/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- sn_neuronal_loss: 6/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_infarcs: 3/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_ri: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_aa_a: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_aa_b: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_aa_c: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- TDP43: 32/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- arteriolosclerosis_severity_scale: 70/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- amyloid_angiopathy_severity_scale: 88/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_ad_level: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- dig_slide_avail: 94/94 empty rows (OPTIONAL)\n",
      "\n",
      "\t- quant_path_avail: 94/94 empty rows (OPTIONAL)\n",
      "No invalid entries found in Enum fields.\n",
      "\n",
      "Loading SAMPLE table\n",
      "All required fields are present in *SAMPLE* table.\n",
      "🚨⚠️❗ **Missing Optional Fields in SAMPLE: ASAP_sample_id, ASAP_subject_id, ASAP_dataset_id, ASAP_team_id, condition, time, alternate_id**\n",
      "🚨⚠️❗ **1 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- source_sample_id: 97/97 empty rows (REQUIRED)\n",
      "No invalid entries found in Enum fields.\n",
      "\n",
      "Table ASSAY_scRNAseq does not exist\n",
      "Loading DATA table\n",
      "All required fields are present in *DATA* table.\n",
      "🚨⚠️❗ **Missing Optional Fields in DATA: ASAP_sample_id, ASAP_subject_id, ASAP_dataset_id, ASAP_team_id**\n",
      "🚨⚠️❗ **3 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- header: 1552/1552 empty rows (OPTIONAL)\n",
      "\n",
      "\t- annotation: 1552/1552 empty rows (OPTIONAL)\n",
      "\n",
      "\t- configuration_file: 1552/1552 empty rows (OPTIONAL)\n",
      "No invalid entries found in Enum fields.\n",
      "\n",
      "Table PMDBS does not exist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tables = {}\n",
    "for table in CDE_df[\"Table\"].unique():\n",
    "    # load table\n",
    "    table_path = test_path / f\"{table}.csv\"\n",
    "\n",
    "    if not table_path.exists():\n",
    "        print(f\"Table {table} does not exist\")\n",
    "    else:\n",
    "        df = pd.read_csv(table_path,dtype=\"str\")\n",
    "        df.replace({\"\":NULL, pd.NA:NULL}, inplace=True)\n",
    "\n",
    "        tables[table] = df\n",
    "        print(f\"Loading {table} table\")\n",
    "\n",
    "\n",
    "        specific_cde_df = CDE_df[CDE_df['Table'] == table]\n",
    "        report = ReportCollector(\"log\")\n",
    "\n",
    "        df_out, report = validate_table(df,table, specific_cde_df, report)\n",
    "        report.print_log()\n",
    "      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['STUDY', 'PROTOCOL', 'SUBJECT', 'CLINPATH', 'SAMPLE', 'DATA'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>source_subject_id</th>\n",
       "      <th>duration_pmi</th>\n",
       "      <th>path_autopsy_dx_main</th>\n",
       "      <th>path_autopsy_second_dx</th>\n",
       "      <th>path_autopsy_third_dx</th>\n",
       "      <th>path_autopsy_fourth_dx</th>\n",
       "      <th>path_autopsy_fifth_dx</th>\n",
       "      <th>path_autopsy_sixth_dx</th>\n",
       "      <th>...</th>\n",
       "      <th>path_nia_ri</th>\n",
       "      <th>path_nia_aa_a</th>\n",
       "      <th>path_nia_aa_b</th>\n",
       "      <th>path_nia_aa_c</th>\n",
       "      <th>TDP43</th>\n",
       "      <th>arteriolosclerosis_severity_scale</th>\n",
       "      <th>amyloid_angiopathy_severity_scale</th>\n",
       "      <th>path_ad_level</th>\n",
       "      <th>dig_slide_avail</th>\n",
       "      <th>quant_path_avail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BN0009</td>\n",
       "      <td>00-09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PD/Dem</td>\n",
       "      <td>Charcot-Marie-Tooth disease (history)</td>\n",
       "      <td>GBA L444P/WT, L444P mutation</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BN0329</td>\n",
       "      <td>03-29</td>\n",
       "      <td>4.5</td>\n",
       "      <td>PD/Dem</td>\n",
       "      <td>Seizure disorder (history)</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BN0339</td>\n",
       "      <td>03-39</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Control</td>\n",
       "      <td>Non-diagnostic Alzheimer's changes</td>\n",
       "      <td>CAA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BN0341</td>\n",
       "      <td>03-41</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Control</td>\n",
       "      <td>Non-diagnostic Alzheimer's changes</td>\n",
       "      <td>CWMR</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>No</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Mild</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BN0347</td>\n",
       "      <td>03-47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Control (MCI)</td>\n",
       "      <td>Non-diagnostic Alzheimer's changes</td>\n",
       "      <td>Argyrophilic grains, mesial temporal lobe</td>\n",
       "      <td>Infarct(s)</td>\n",
       "      <td>CWMR</td>\n",
       "      <td>Several microscopic foci of cerebellar cortica...</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Mild</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>BN2003</td>\n",
       "      <td>20-03</td>\n",
       "      <td>2.65</td>\n",
       "      <td>PD/Dem</td>\n",
       "      <td>Microscopic changes of Alzheimer's disease, in...</td>\n",
       "      <td>Focal non-specific glial tauopathy, cortex of ...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>No</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>BN2015</td>\n",
       "      <td>20-15</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Control (history)</td>\n",
       "      <td>Microscopic changes of Alzheimer's disease, in...</td>\n",
       "      <td>Incidental Lewy body disease</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>No</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>BN9944</td>\n",
       "      <td>99-44</td>\n",
       "      <td>2.16</td>\n",
       "      <td>Control</td>\n",
       "      <td>Non-diagnostic Alzheimer's changes</td>\n",
       "      <td>Alzheimer Type II astrocytosis consistent with...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>BN9947</td>\n",
       "      <td>99-47</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Control</td>\n",
       "      <td>Non-diagnostic Alzheimer's changes</td>\n",
       "      <td>Alzheimer type II astrocytosis</td>\n",
       "      <td>Inc LBs</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>BN9966</td>\n",
       "      <td>99-66</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Control</td>\n",
       "      <td>Incidental LBs</td>\n",
       "      <td>Non-diagnostic Alzheimer's changes</td>\n",
       "      <td>Argyrophilic grains in mesial temporal lobe</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Mild</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 subject_id source_subject_id duration_pmi path_autopsy_dx_main  \\\n",
       "0           0     BN0009             00-09          4.0               PD/Dem   \n",
       "1           1     BN0329             03-29          4.5               PD/Dem   \n",
       "2           2     BN0339             03-39         2.75              Control   \n",
       "3           3     BN0341             03-41          2.5              Control   \n",
       "4           4     BN0347             03-47          3.5        Control (MCI)   \n",
       "..        ...        ...               ...          ...                  ...   \n",
       "89         89     BN2003             20-03         2.65               PD/Dem   \n",
       "90         90     BN2015             20-15          5.4    Control (history)   \n",
       "91         91     BN9944             99-44         2.16              Control   \n",
       "92         92     BN9947             99-47          2.5              Control   \n",
       "93         93     BN9966             99-66          2.0              Control   \n",
       "\n",
       "                               path_autopsy_second_dx  \\\n",
       "0               Charcot-Marie-Tooth disease (history)   \n",
       "1                          Seizure disorder (history)   \n",
       "2                  Non-diagnostic Alzheimer's changes   \n",
       "3                  Non-diagnostic Alzheimer's changes   \n",
       "4                  Non-diagnostic Alzheimer's changes   \n",
       "..                                                ...   \n",
       "89  Microscopic changes of Alzheimer's disease, in...   \n",
       "90  Microscopic changes of Alzheimer's disease, in...   \n",
       "91                 Non-diagnostic Alzheimer's changes   \n",
       "92                 Non-diagnostic Alzheimer's changes   \n",
       "93                                     Incidental LBs   \n",
       "\n",
       "                                path_autopsy_third_dx  \\\n",
       "0                        GBA L444P/WT, L444P mutation   \n",
       "1                                                  NA   \n",
       "2                                                 CAA   \n",
       "3                                                CWMR   \n",
       "4           Argyrophilic grains, mesial temporal lobe   \n",
       "..                                                ...   \n",
       "89  Focal non-specific glial tauopathy, cortex of ...   \n",
       "90                       Incidental Lewy body disease   \n",
       "91  Alzheimer Type II astrocytosis consistent with...   \n",
       "92                     Alzheimer type II astrocytosis   \n",
       "93                 Non-diagnostic Alzheimer's changes   \n",
       "\n",
       "                         path_autopsy_fourth_dx path_autopsy_fifth_dx  \\\n",
       "0                                            NA                    NA   \n",
       "1                                            NA                    NA   \n",
       "2                                            NA                    NA   \n",
       "3                                            NA                    NA   \n",
       "4                                    Infarct(s)                  CWMR   \n",
       "..                                          ...                   ...   \n",
       "89                                           NA                    NA   \n",
       "90                                           NA                    NA   \n",
       "91                                           NA                    NA   \n",
       "92                                      Inc LBs                    NA   \n",
       "93  Argyrophilic grains in mesial temporal lobe                    NA   \n",
       "\n",
       "                                path_autopsy_sixth_dx  ... path_nia_ri  \\\n",
       "0                                                  NA  ...          NA   \n",
       "1                                                  NA  ...          NA   \n",
       "2                                                  NA  ...          NA   \n",
       "3                                                  NA  ...          NA   \n",
       "4   Several microscopic foci of cerebellar cortica...  ...          NA   \n",
       "..                                                ...  ...         ...   \n",
       "89                                                 NA  ...          NA   \n",
       "90                                                 NA  ...          NA   \n",
       "91                                                 NA  ...          NA   \n",
       "92                                                 NA  ...          NA   \n",
       "93                                                 NA  ...          NA   \n",
       "\n",
       "   path_nia_aa_a path_nia_aa_b path_nia_aa_c TDP43  \\\n",
       "0             NA            NA            NA    NA   \n",
       "1             NA            NA            NA    NA   \n",
       "2             NA            NA            NA    NA   \n",
       "3             NA            NA            NA    No   \n",
       "4             NA            NA            NA    NA   \n",
       "..           ...           ...           ...   ...   \n",
       "89            NA            NA            NA    No   \n",
       "90            NA            NA            NA    No   \n",
       "91            NA            NA            NA    NA   \n",
       "92            NA            NA            NA    NA   \n",
       "93            NA            NA            NA    NA   \n",
       "\n",
       "   arteriolosclerosis_severity_scale amyloid_angiopathy_severity_scale  \\\n",
       "0                                 NA                                NA   \n",
       "1                                 NA                                NA   \n",
       "2                               Mild                          Moderate   \n",
       "3                           Moderate                              Mild   \n",
       "4                               Mild                                NA   \n",
       "..                               ...                               ...   \n",
       "89                                NA                                NA   \n",
       "90                                NA                                NA   \n",
       "91                                NA                                NA   \n",
       "92                                NA                                NA   \n",
       "93                                NA                              Mild   \n",
       "\n",
       "   path_ad_level dig_slide_avail quant_path_avail  \n",
       "0             NA              NA               NA  \n",
       "1             NA              NA               NA  \n",
       "2             NA              NA               NA  \n",
       "3             NA              NA               NA  \n",
       "4             NA              NA               NA  \n",
       "..           ...             ...              ...  \n",
       "89            NA              NA               NA  \n",
       "90            NA              NA               NA  \n",
       "91            NA              NA               NA  \n",
       "92            NA              NA               NA  \n",
       "93            NA              NA               NA  \n",
       "\n",
       "[94 rows x 37 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[\"CLINPATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
